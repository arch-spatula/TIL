# 블로그 다시 만들기 99일차

1일1커밋 무사고: 1030일차

## 감사일기

1. ???

## todo

- [ ] Do it C++ 코딩 테스트
  - [ ] 3일차
    - [ ] 구간 합
- [ ] 마이크로 튜토리얼
  - [ ] Chapter 4 - Request Lines
  - [ ] Chapter 5 - HTTP Headers
  - [ ] Chapter 6 - HTTP Body
  - [ ] Chapter 7 - HTTP Responses
  - [ ] Chapter 8 - Chunked Encoding
  - [ ] Chapter 9 - Binary Data
- [ ] 블로그 다시 만들기 전 실험
  - [ ] vite로 github pages가 정적 리소스 응답하는 방식 흉내내기
  - [ ] ToC
    - [ ] `data.json`에 h1 ~ h6에 해당하는 데이터 추가
    - [ ] DOM에 붙이기
  - [ ] 검색 팝업에서 tag 클랙해도 input 상태 보존하기

---

## 블로그 만들기 2차 실험

- 블로그를 만들면서 마음에 드는 부분이 있고 아닌 부분이 있습니다.
- vite로 모든 것을 빌드타임으로 옮겨서 처리하는 것은 적절하다고 생각합니다. dist는 순수하게 html만 있어야 합니다.
- MPA라고 말하면서 SPA처럼 임의로 DOM 생성하는 것이 너무 많습니다. `display: none`으로 처리하면 자바스크립트 DOM 생성 오버해드를 줄일 수 있을 것 같습니다.
  - 임의로 DOM을 생성하는 로직은 모두 빌드타임에 처리되야 할 것 같습니다.
  - 런타임에는 보여주고 말고 할 제어 클래스만 존재해야 합니다.
- MPA라고 해도 깜박임 현상을 제거할 수 있다고 생각합니다. 이 현상을 올바르게 해결해야 합니다.
- 마크다운 파일의 위치가 public이 아니라서 img를 결국에는 로컬에서 2배로 만들게 될 설계를 했습니다. 굳이 public이 아니라는 제약을 풀어버리기 위한 저의 욕심이었습니다.
  - 이 부분은 오히려 포기하고 public 내에서 마크다운 파일을 작성하고 하위에 이미지를 같이 위치 시키면 단일 이미지로 처리가 가능했을 것 같습니다.
  - 빌드타임에 마크다운 파싱이 끝나면 마크다운 파일을 제거해달라고 하면 되는 것이었습니다. 또 마크다운 파일은 굳이 공개할 파일인데 리소스 경로로 알아낸다고 치명적일 것 같지 않습니다.
- github pages같은 리소스 경로와 로컬 개발환경에서 다르게 만들 이유가 없는데 굳이 달랐던 부분이 많습니다.
- 초기화 시점에 상태관리를 잘 못했습니다.
  - url에서 활용할 값들은 쿼리파라미터가 아니라 해시를 사용했어야 합니다. 네이티브를 주장하면서 네이티브가 아니었습니다. 물론 제어하기 위한 관점에서는 편리한 점들이 있었습니다.
  - 초기화 작업을 동기적으로 처리할 때는 init으로 1번만 처리했어야 합니다.
- vite랑 타입스크립트라는 툴을 중심으로 개발한 것은 올바른 선택이었습니다. 로컬 개발환경에 node.js를 위한 DAP 설정만 하면 될 것 같습니다.
- 이런 기능을 다시 만들 때는 다른 별도의 레포가 더 필요할지 의문입니다.
  - 지금 말한 단점들이 별도의 레포에서 1번 더 실험이 필요 할 정도로 큰 변화인지 생각해봐야 합니다.
  - 무슨 로직을 언제 실행할지 시점 제어와 파일 위치가 다르다는 것 정도 다릅니다.
  - 그냥 본인 블로그를 fork하고 작업하면 됩니다.

## 구간 합 구하기 1

- https://www.acmicpc.net/problem/11659
- 구간 합 구하기 4

```cpp
#include <iostream>
#include <ostream>
#include <vector>

int main() {
  int size = 0;
  int query = 0;
  std::cin >> size >> query;

  std::vector<int> array(size);
  std::vector<int> subSum(size);
  int i = 0;
  for (; i < size; i++) {
    std::cin >> array[i];
    if (i == 0) {
      subSum[i] = array[i];
    } else {
      subSum[i] = array[i] + subSum[i - 1];
    }
  }
  i = 0;
  for (; i < query; i++) {
    int startIdx = 0;
    int endIdx = 0;
    std::cin >> startIdx >> endIdx;
    startIdx -= 2;
    endIdx -= 1;
    if (startIdx == -1) {
      std::cout << subSum[endIdx] << std::endl;
    } else {
      std::cout << subSum[endIdx] - subSum[startIdx] << std::endl;
    }
  }
  return 0;
}
```

- 위는 1차 시도입니다. 시간복잡성의 기울기 값을 높이는 로직들이 들어있습니다.
- 문제의 정답을 확인해보니 굳이 배열을 2개로 관리할 이유가 없습니다.
- 0번째 인덱스에 0으로 넣으면 굳이 필요없는 분기처리도 제거할 수 있습니다.
- 정답을 봐도 정답의 특징만 이해하고 다시 작성하고 다시 풀어보는 것이 적절할 것 같습니다.
- 표준입력으로 로직 자체는 맞습니다. 하지만 시간 복잡성이 높습니다.

```cpp
#include <iostream>
#include <ostream>
#include <vector>

int main() {
  int size = 0;
  int query = 0;
  std::cin >> size >> query;

  std::vector<int> subSum(size + 1);
  subSum[0] = 0;
  int i = 1;
  for (; i <= size; i++) {
    int temp;
    std::cin >> temp;
    subSum[i] = temp + subSum[i - 1];
  }
  i = 0;
  for (; i < query; i++) {
    int startIdx = 0;
    int endIdx = 0;
    std::cin >> startIdx >> endIdx;
    std::cout << subSum[endIdx] - subSum[startIdx - 1] << std::endl;
  }
  return 0;
}
```

- 부분합의 시간 복잡성 기울기를 줄였습니다. 하지만 여전히 통과를 못했습니다. 시간초과가 발생했습니다.

## 백엔드는 PostgreSQL 하나로 끝 (DB 비용 반으로 줄이는 방법)

- https://www.youtube.com/watch?v=OZrmFD2ajlQ
- 백엔드는 PostgreSQL 하나로 끝 (DB 비용 반으로 줄이는 방법)
- 현대 웹 개발의 복잡성을 PG를 BaaS로 해결가능하다고 주장합니다. 이 주장을 직접 검증하려면 제가 직접 만들어봐야 할 것 같습니다.
- 캐싱은 unlogged 테이블로 해결한다고 합니다.
  - WAL을 건너뛴다고 합니다.
  - 메모리에 상주시켜서 레디스와 비슷한 성능을 낸다고 합니다.
  - 쓰기 작업이 많은 임시 데이터에 좋다고 합니다. 마치 인증인가가 해당하는 것 같습니다.
- 크론 작업은 pg_cron 확장으로 해결가능하다고 합니다.
- 고급 검색 기능은 벡터를 추가하는 것으로 해결가능하다고 합니다.
- 보안은 pgcrypto랑 RLS 정책으로 해결할 수 있다고 합니다.
- 가벼운 백엔드 플랫폼이 된다고 할 때 말이 되는 것 같습니다.
- 이런 영상을 본다면 극도로 단순하고 툴이 없는 백엔드 라이브러리만 붙이면 MVP를 뽑는 것이 어려워 보이지 않습니다.
- 굳이 만들어보겠다는 생각하면 express.js 아니면 flask로 API와 정적 파일처리만 해주고 나머지 베터리 로직은 PG로 해결할 수 있다는 생각이 듭니다. 더 생각해보니까 go 언어 1개로 해결하는 것도 가능할 것 같다는 생각이 들었습니다.
  - 당연히 보안은 담보할 수 없습니다.

### WAL란 무엇인가?

- 로그 선행 기입 (Write-ahead logging)이라고 부르는 듯합니다.
- https://ko.wikipedia.org/wiki/%EB%A1%9C%EA%B7%B8_%EC%84%A0%ED%96%89_%EA%B8%B0%EC%9E%85
- 재해복구를 위해 로그를 먼저 저장하고 그다음에 테이블을 갱신합니다.
- 재해복구의 수준은 정전 같은 경우입니다. 모든 작업이 성공했는지 일부만 성공했는지 실패했는지 알아야합니다.
- 인플레이스 알고리즘, 그림자 페이징, ARIES이 언급되었습니다.

